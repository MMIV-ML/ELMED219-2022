{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9579e4dd-b2a3-4928-b913-552a972ccbd4",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550462f0-c14f-41bd-8e0c-05178529382a",
   "metadata": {},
   "source": [
    "This notebook gives a quick example of using Transformers for NLP. It is meant to demystify these state-of-the-art models (the coe below isn't _that_ different from other things you've seen earlier in the course). \n",
    "\n",
    "It will be very superficial. Have a look at the [HuggingFace course](https://huggingface.co/course/chapter1/1) and their great documentation over at https://huggingface.co/transformers for more, if you're interested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431fdfd-334f-4c62-9d5d-02ed08339470",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center;\" ><a href=\"https://huggingface.co/course/chapter1/1\"><img src=\"https://huggingface.co/front/assets/course-logo.svg\"></a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b865c9-4f82-4aae-b596-a7c9ed6e9d0e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e265cca-ad9e-4099-9540-10cbbf5f852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The notebook is not running on Colab. colab=False.\n"
     ]
    }
   ],
   "source": [
    "# This is a quick check of whether the notebook is currently running \n",
    "# on Google Colaboratory\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('The notebook is running on Colab. colab=True.')\n",
    "    colab=True\n",
    "else:\n",
    "    print('The notebook is not running on Colab. colab=False.')\n",
    "    colab=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4359823-c8e1-42be-8bd8-f1c1ccd477c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a632e78-a0d3-486b-b121-369e4df91be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install -Uqq fastbook\n",
    "    import fastbook\n",
    "    from fastbook import *\n",
    "    !pip install git+https://github.com/huggingface/transformers.git datasets\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    DATA = Path(\"/content/gdrive/MyDrive/Colab Notebooks/elmed219-data\")\n",
    "    DATA.mkdir(exist_ok=True)\n",
    "if not colab:\n",
    "    DATA=Path('./data')\n",
    "    DATA.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afed5cd6-89ed-4049-b0e4-844c6885ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a05267cd-0918-419c-9dd8-1b22c5c1ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5af3387f-6096-42f7-af84-0e278e9515ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8112181-8b08-45f9-b039-9c8825ca2781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998704195022583}]\n"
     ]
    }
   ],
   "source": [
    "# Verify that the transformers library is installed and operational\n",
    "import transformers\n",
    "print(transformers.pipeline('sentiment-analysis')('we love you'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f6f4d78-51c4-4616-b413-d16eaa3a2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          PreTrainedModel, BertModel, BertForSequenceClassification,\n",
    "                          TrainingArguments, Trainer)\n",
    "\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33283de-aff5-4677-8977-04503956e199",
   "metadata": {},
   "source": [
    "# MedWeb using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5bd54a-91ed-4905-bf08-d9191e660be2",
   "metadata": {},
   "source": [
    "Load the data as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "138dd6ab-57ec-47fb-96d3-2f8ea31590e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Influenza</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>Hayfever</th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Runnynose</th>\n",
       "      <th>Cold</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1en</td>\n",
       "      <td>The cold makes my whole body weak.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cold</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2en</td>\n",
       "      <td>It's been a while since I've had allergy symptoms.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hayfever;Runnynose</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3en</td>\n",
       "      <td>I'm so feverish and out of it because of my allergies. I'm so sleepy.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hayfever;Fever;Runnynose</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4en</td>\n",
       "      <td>I took some medicine for my runny nose, but it won't stop.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Runnynose</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5en</td>\n",
       "      <td>I had a bad case of diarrhea when I traveled to Nepal.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sober</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                                                  Tweet  \\\n",
       "0  1en                                     The cold makes my whole body weak.   \n",
       "1  2en                     It's been a while since I've had allergy symptoms.   \n",
       "2  3en  I'm so feverish and out of it because of my allergies. I'm so sleepy.   \n",
       "3  4en             I took some medicine for my runny nose, but it won't stop.   \n",
       "4  5en                 I had a bad case of diarrhea when I traveled to Nepal.   \n",
       "\n",
       "   Influenza  Diarrhea  Hayfever  Cough  Headache  Fever  Runnynose  Cold  \\\n",
       "0          0         0         0      0         0      0          0     1   \n",
       "1          0         0         1      0         0      0          1     0   \n",
       "2          0         0         1      0         0      1          1     0   \n",
       "3          0         0         0      0         0      0          1     0   \n",
       "4          0         0         0      0         0      0          0     0   \n",
       "\n",
       "                     labels  is_test  \n",
       "0                      Cold    False  \n",
       "1        Hayfever;Runnynose    False  \n",
       "2  Hayfever;Fever;Runnynose    False  \n",
       "3                 Runnynose    False  \n",
       "4                     sober    False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://github.com/MMIV-ML/ELMED219-2022/raw/main/Lab2-NLP/data/medwebdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59355ecf-9ea6-43f2-b0a6-d30d69e4d7ac",
   "metadata": {},
   "source": [
    "For convenience, we combine all the labels into one vector stored under `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40a28a66-35a5-40e7-8a54-037015239657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['is_test','labels'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe100807-13e2-4f39-81a4-c803b9538a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df.apply(lambda x: [x[c] for c in df.columns[2:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bdb83b17-8d4f-4938-b751-329a5285e532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Influenza</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>Hayfever</th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Runnynose</th>\n",
       "      <th>Cold</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1en</td>\n",
       "      <td>The cold makes my whole body weak.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2en</td>\n",
       "      <td>It's been a while since I've had allergy symptoms.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3en</td>\n",
       "      <td>I'm so feverish and out of it because of my allergies. I'm so sleepy.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4en</td>\n",
       "      <td>I took some medicine for my runny nose, but it won't stop.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5en</td>\n",
       "      <td>I had a bad case of diarrhea when I traveled to Nepal.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                                                  Tweet  \\\n",
       "0  1en                                     The cold makes my whole body weak.   \n",
       "1  2en                     It's been a while since I've had allergy symptoms.   \n",
       "2  3en  I'm so feverish and out of it because of my allergies. I'm so sleepy.   \n",
       "3  4en             I took some medicine for my runny nose, but it won't stop.   \n",
       "4  5en                 I had a bad case of diarrhea when I traveled to Nepal.   \n",
       "\n",
       "   Influenza  Diarrhea  Hayfever  Cough  Headache  Fever  Runnynose  Cold  \\\n",
       "0          0         0         0      0         0      0          0     1   \n",
       "1          0         0         1      0         0      0          1     0   \n",
       "2          0         0         1      0         0      1          1     0   \n",
       "3          0         0         0      0         0      0          1     0   \n",
       "4          0         0         0      0         0      0          0     0   \n",
       "\n",
       "                     labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "1  [0, 0, 1, 0, 0, 0, 1, 0]  \n",
       "2  [0, 0, 1, 0, 0, 1, 1, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f064f2-05ab-49fd-bffe-c38557a85bf2",
   "metadata": {},
   "source": [
    "Set up the transformers model. We'll use the [PubMedBERT model](https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract) created by Microsoft Research by training a BERT model on 14 million abstracts of PubMed articles. \n",
    "\n",
    "Have a look at the blog post [Domain-specific language model pretraining for biomedical natural language processing](https://www.microsoft.com/en-us/research/blog/domain-specific-language-model-pretraining-for-biomedical-natural-language-processing/) and the accompanying paper. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b2aa595b-af89-414f-a393-bd4947c1946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract'\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01dda1-4107-452f-97bf-e48d420d90cf",
   "metadata": {},
   "source": [
    "We need to tokenize the data in the same way as the original PubMed dataset and create a data set compatible with HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a2769602-4e6d-411c-b55b-89eb70134b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eb6b03c-d5e7-405b-a6bf-cf8e293d0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df, split='train').train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2113adc5-ec52-4b88-9d63-1ff9bb974725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Tweet', 'Influenza', 'Diarrhea', 'Hayfever', 'Cough', 'Headache', 'Fever', 'Runnynose', 'Cold', 'labels'],\n",
       "        num_rows: 1920\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'Tweet', 'Influenza', 'Diarrhea', 'Hayfever', 'Cough', 'Headache', 'Fever', 'Runnynose', 'Cold', 'labels'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4e2aeb9-4923-40bf-82cb-2c1e97c758b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': '351en',\n",
       " 'Tweet': \"I can't call in sick for a fever, so I'm taking medicine for it.\",\n",
       " 'Influenza': 0,\n",
       " 'Diarrhea': 0,\n",
       " 'Hayfever': 0,\n",
       " 'Cough': 0,\n",
       " 'Headache': 0,\n",
       " 'Fever': 1,\n",
       " 'Runnynose': 0,\n",
       " 'Cold': 0,\n",
       " 'labels': [0, 0, 0, 0, 0, 1, 0, 0]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f1edf869-145a-4d80-9c49-dc32e056e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(examples[\"Tweet\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4497d345-b66d-4f66-a9e1-d9bd6c04f968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c65f74253674f21b96417084e10dc06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b72903e89cc43c98e09bcaf4e746a59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ds['train'].column_names\n",
    "cols.remove('labels')\n",
    "ds_enc = ds.map(tokenize_and_encode, batched=True, remove_columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47e36eec-4ba5-426d-b644-41ae6bdd0d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 1920\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'token_type_ids'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0af2134a-a1e6-4b1f-b845-c3379a26aa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForMultilabelSequenceClassification(BertForSequenceClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "    def forward(self,\n",
    "        input_ids=None,\n",
    "        attention_mask=None,\n",
    "        token_type_ids=None,\n",
    "        position_ids=None,\n",
    "        head_mask=None,\n",
    "        inputs_embeds=None,\n",
    "        labels=None,\n",
    "        output_attentions=None,\n",
    "        output_hidden_states=None,\n",
    "        return_dict=None):\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict)\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        logits = self.classifier(pooled_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), \n",
    "                            labels.float().view(-1, self.num_labels))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cc33f4b-19b6-4b1a-b6ce-38932fc79a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForMultilabelSequenceClassification: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForMultilabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMultilabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMultilabelSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels=8\n",
    "model = BertForMultilabelSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bf238-5e42-4380-abe0-dc694017155f",
   "metadata": {},
   "source": [
    "We define some metrics to use when scoring on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84c19021-aab7-4fc7-b7b0-945b1ebfc219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def accuracy_thresh(y_pred, y_true, thresh=0.5, sigmoid=True): \n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    if sigmoid: \n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred>thresh)==y_true.bool()).float().mean().item()\n",
    "\n",
    "def f1score_thresh(y_pred, y_true, average='micro',thresh=0.5, sigmoid=True): \n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    if sigmoid: \n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return f1_score(y_true, y_pred>thresh, average='micro')\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return {'accuracy_thresh': accuracy_thresh(predictions, labels),\n",
    "           'f1score_micro_thresh': f1score_thresh(predictions, labels, average='micro'),\n",
    "           'f1score_macro_thresh': f1score_thresh(predictions, labels, average='macro')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578303e-dfdf-457f-91a9-dc38741313b9",
   "metadata": {},
   "source": [
    "..and then the training setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe88e2a3-34f8-4a26-819f-091eade0e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\".\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=6,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a39ab6b1-950c-42ec-966f-3f8550c10d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=ds_enc[\"train\"],\n",
    "    eval_dataset=ds_enc[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e46042-53d8-4c77-87b2-c22df00cc963",
   "metadata": {},
   "source": [
    "Let's see how the model does without any training on the MedWeb data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8bdac7f-a432-47eb-8a31-3e8f7123ca3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 16\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='80' max='40' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [40/40 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.788185179233551,\n",
       " 'eval_accuracy_thresh': 0.28535157442092896,\n",
       " 'eval_f1score_micro_thresh': 0.20231087856987137,\n",
       " 'eval_f1score_macro_thresh': 0.20231087856987137,\n",
       " 'eval_runtime': 8.4103,\n",
       " 'eval_samples_per_second': 76.098,\n",
       " 'eval_steps_per_second': 4.756}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa62db2-5379-40ad-b9d7-c4a22abbf46f",
   "metadata": {},
   "source": [
    "Then fine-tune it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "385f8a8f-4987-44bc-826f-7ad4412c76cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running training *****\n",
      "  Num examples = 1920\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 720\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='720' max='720' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [720/720 04:37, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1score Micro Thresh</th>\n",
       "      <th>F1score Macro Thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.190666</td>\n",
       "      <td>0.948438</td>\n",
       "      <td>0.775891</td>\n",
       "      <td>0.775891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.133730</td>\n",
       "      <td>0.966602</td>\n",
       "      <td>0.870159</td>\n",
       "      <td>0.870159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.110169</td>\n",
       "      <td>0.971680</td>\n",
       "      <td>0.883534</td>\n",
       "      <td>0.883534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.098374</td>\n",
       "      <td>0.972266</td>\n",
       "      <td>0.887658</td>\n",
       "      <td>0.887658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.097016</td>\n",
       "      <td>0.972266</td>\n",
       "      <td>0.886218</td>\n",
       "      <td>0.886218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.095269</td>\n",
       "      <td>0.972852</td>\n",
       "      <td>0.889066</td>\n",
       "      <td>0.889066</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 16\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 16\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 16\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 16\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "Saving model checkpoint to ./checkpoint-500\n",
      "Configuration saved in ./checkpoint-500/config.json\n",
      "Model weights saved in ./checkpoint-500/pytorch_model.bin\n",
      "tokenizer config file saved in ./checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./checkpoint-500/special_tokens_map.json\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 16\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=720, training_loss=0.1411350131034851, metrics={'train_runtime': 277.6708, 'train_samples_per_second': 41.488, 'train_steps_per_second': 2.593, 'total_flos': 231566647346688.0, 'train_loss': 0.1411350131034851, 'epoch': 6.0})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e1fdef-a045-4d85-b4b3-01f8ae2a145f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Another example: The Genetic Association Database (GAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83db213-6083-43bf-a5d3-e70eb0f2d6dc",
   "metadata": {},
   "source": [
    "For this example we'll use GAD, which contains gene-disease relations, based on the data set prepeared by BioBERT: https://github.com/dmis-lab/biobert. Have a look at [Becker, Kevin G., et al. \"The genetic association database.\" Nature genetics 36.5 (2004): 431-432.](https://geneticassociationdb.nih.gov/gad.pdf) for details about the database.\n",
    "\n",
    "Let's try to fine-tune a model to perform a new task. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05338810-c4ce-41c9-933e-a0443112e369",
   "metadata": {},
   "source": [
    "# Get a pretrained model and tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d100f6f-bd05-4c80-ac6f-058ffbf92b40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "244e8182260341b181d3806341ec572f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c23f8d62e34f81b5d3aaf5e65b89ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract'\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5c92d87-3b81-477e-9c38-921ad386585b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c945ceaa05f64baeaf5214ea93057050",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c89bade2-7969-4c0f-9e95-daec61b4072f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2280, 2606, 3275, 1760, 1680, 35, 2397, 7, 16, 12851, 1013, 18, 42, 6343, 4042, 1888, 3568, 42, 5945, 2467, 1682, 3056, 15831, 1701, 35, 2174, 7, 1682, 1805, 7910, 2806, 17, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(\"\"\"Our findings indicate that the @GENE$-112G/A polymorphism \n",
    "          does not play a substantial role in genetic predisposition to @DISEASE$ in this Japanese population.\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93488b09-7534-44e7-b0a2-e361873f8474",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Genetic Association Database (GAD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c583d7b7-9e48-4395-830b-90e57db23d66",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ed78289-63c4-46ed-a68b-d48e0fc0048d",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.dropbox.com/s/s91q5kp6ausq9cj/REdata.zip?dl=1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01034b45-9387-4678-8a65-7b1a1edb33e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile(DATA/'REdata.zip'):\n",
    "    urllib.request.urlretrieve(url, DATA/'REdata.zip')\n",
    "    shutil.unpack_archive(DATA/'REdata.zip', extract_dir=DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "016f1ce4-acc2-4ac4-8a8e-7c17529e01e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GAD = DATA/'GAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f73589-2189-47fc-9f8b-eed41207fdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#11) [Path('/home/alex/data-tmp/huggingface/GAD/6'),Path('/home/alex/data-tmp/huggingface/GAD/5'),Path('/home/alex/data-tmp/huggingface/GAD/models'),Path('/home/alex/data-tmp/huggingface/GAD/9'),Path('/home/alex/data-tmp/huggingface/GAD/2'),Path('/home/alex/data-tmp/huggingface/GAD/10'),Path('/home/alex/data-tmp/huggingface/GAD/4'),Path('/home/alex/data-tmp/huggingface/GAD/3'),Path('/home/alex/data-tmp/huggingface/GAD/7'),Path('/home/alex/data-tmp/huggingface/GAD/8')...]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GAD.ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "528d6631-c046-40e8-8952-4c7634fabc63",
   "metadata": {},
   "source": [
    "## Explore data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba109a9f-5118-4e3b-a85a-34b8788b4f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max.colwidth', 1000)\n",
    "pd.set_option('display.html.use_mathjax', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e04d280a-8721-421d-9a00-2fd04d6b3fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_fn = GAD/'5'/'train.tsv'\n",
    "df = pd.read_csv(example_fn, sep='\\t', header=None, names=['text', 'interaction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30816144-0c7b-47bc-b9d4-40e99710be47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe tex2jax_ignore\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>interaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An interaction with hypertension in the association between the @GENE$ G460W polymorphism and @DISEASE$ merits further testing in additional populations.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Our study suggests that the five SNPs within @GENE$ gene we studied may not play a major role in the @DISEASE$ susceptibility in the Chinese Han population.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our findings suggest that the @GENE$ polymorphism is not associated with an increased risk of squamous cell @DISEASE$ in Korean women.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Our findings indicate that the @GENE$-112G/A polymorphism does not play a substantial role in genetic predisposition to @DISEASE$ in this Japanese population.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Although an increasing number of studies report an association between the @GENE$ G1385A variant and @DISEASE$ risk; this variant does not appear to be implicated in the development of breast cancer.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                      text  \\\n",
       "0                                                An interaction with hypertension in the association between the @GENE$ G460W polymorphism and @DISEASE$ merits further testing in additional populations.   \n",
       "1                                             Our study suggests that the five SNPs within @GENE$ gene we studied may not play a major role in the @DISEASE$ susceptibility in the Chinese Han population.   \n",
       "2                                                                   Our findings suggest that the @GENE$ polymorphism is not associated with an increased risk of squamous cell @DISEASE$ in Korean women.   \n",
       "3                                           Our findings indicate that the @GENE$-112G/A polymorphism does not play a substantial role in genetic predisposition to @DISEASE$ in this Japanese population.   \n",
       "4  Although an increasing number of studies report an association between the @GENE$ G1385A variant and @DISEASE$ risk; this variant does not appear to be implicated in the development of breast cancer.   \n",
       "\n",
       "   interaction  \n",
       "0            1  \n",
       "1            1  \n",
       "2            1  \n",
       "3            0  \n",
       "4            0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "624c4dc5-a418-4dba-b5e1-19cfb8318878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2521\n",
       "0    2276\n",
       "Name: interaction, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.interaction.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c775c8-a8ca-4959-879a-773e55d8dd23",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26939197-a129-4064-bdb4-c3f61283c07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gad_split(df):\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for row in df.iterrows():\n",
    "        texts.append(row[1].text)\n",
    "        labels.append(row[1].interaction)\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f31b4c2a-370a-4213-a605-09b10d2938b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = read_gad_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bb52c15-20e9-4169-9345-70110062dd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['An interaction with hypertension in the association between the @GENE$ G460W polymorphism and @DISEASE$ merits further testing in additional populations.',\n",
       " 'Our study suggests that the five SNPs within @GENE$ gene we studied may not play a major role in the @DISEASE$ susceptibility in the Chinese Han population.',\n",
       " 'Our findings suggest that the @GENE$ polymorphism is not associated with an increased risk of squamous cell @DISEASE$ in Korean women.',\n",
       " 'Our findings indicate that the @GENE$-112G/A polymorphism does not play a substantial role in genetic predisposition to @DISEASE$ in this Japanese population.',\n",
       " 'Although an increasing number of studies report an association between the @GENE$ G1385A variant and @DISEASE$ risk; this variant does not appear to be implicated in the development of breast cancer.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abef560a-bd3a-4567-9022-e6e0172304ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 0, 0]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bfbda74-03be-4e0b-9a80-9c84e8eff54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9a637e9-58a6-4a4d-84e8-470601843b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed8e06ef-16b6-4129-bf0a-f6a3bdda5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_encodings = tokenizer(val_texts, padding=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899ceabb-4eb0-49d2-a333-1adf0dc80c30",
   "metadata": {},
   "source": [
    "### Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8e6769db-66dc-4297-a4c2-5ba9063f079d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fc87e8ee-0476-47ee-b9ac-af51f9b7b62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GADDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9cc57278-6aea-4974-8260-e52ea9b2e8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = GADDataset(train_encodings, train_labels)\n",
    "val_dataset = GADDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25b18ba-c54e-4ba4-ae40-c374302cec96",
   "metadata": {},
   "source": [
    "## Use the pre-trained transformer model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8317ec07-c78b-4bcd-89e1-d42d2cfccdd3",
   "metadata": {},
   "source": [
    "We'll fine-tune the pre-trained model to classify whether the text indicates an interaction or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe7b359d-b628-4086-a2d1-9cd6dff0ce6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS_GDB = DATA/'GAD'/'models'\n",
    "MODELS_GDB.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92e29164-c7e3-45c9-8ffb-51d3c178693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b3a3ec8-3bc4-4ed6-80f1-32d08b2feef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=str(MODELS_GDB/'results'),\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=64,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=str(MODELS_GDB/'logs'),\n",
    "    logging_steps=10\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e1ad852e-44ee-434f-b21d-76edd54f7d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4fda1304-01ee-4351-94df-251f8b8543bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5233b73b-b241-471f-a9c1-d07628b4c418",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 1 which\n",
      "    has less than 75% of the memory or cores of GPU 0. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/alex/anaconda3/envs/fastai/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='120' max='120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [120/120 00:50, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.719800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.718000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.699800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.698200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.696600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.666100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.669300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.666600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.628400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.620700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.598800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.591600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=120, training_loss=0.6644821008046468, metrics={'train_runtime': 52.5067, 'train_samples_per_second': 2.285, 'total_flos': 327669619825080.0, 'epoch': 1.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bec5300-a9aa-4a8a-ab8e-e9377e48dbd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred = trainer.evaluate(eval_dataset=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5896ae6c-9e32-41e1-a262-8d7dedf3dfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5201655030250549,\n",
       " 'eval_accuracy': 0.7479166666666667,\n",
       " 'eval_f1': 0.7734082397003745,\n",
       " 'eval_precision': 0.722027972027972,\n",
       " 'eval_recall': 0.8326612903225806,\n",
       " 'eval_runtime': 2.1733,\n",
       " 'eval_samples_per_second': 441.732,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea7649a-8131-454c-bcc0-49e221c9a7bb",
   "metadata": {},
   "source": [
    "# Possible next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17d3b1e-596e-44cc-abd1-1939a4c4ed52",
   "metadata": {},
   "source": [
    "You can consider trying out the model on other tasks from the benchmark data sets set up by the authors of PubMedBERT [BLURB: Biomedical Language Understanding and Reasoning Benchmark](https://microsoft.github.io/BLURB/) (or any other similar task you may think of)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
